# Import necessary libraries
import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers, models, regularizers
import matplotlib.pyplot as plt
import numpy as np
import os

# Download and extract the cats and dogs dataset
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'
path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)
BASE_DIR = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(BASE_DIR, 'train')
validation_dir = os.path.join(BASE_DIR, 'validation')

print(f"Dataset extracted to: {BASE_DIR}")
print(f"Training images are in: {train_dir}")
print(f"Validation images are in: {validation_dir}")

# Set up image parameters
IMG_SIZE = (224, 224)
BATCH_SIZE = 32
BUFFER_SIZE = tf.data.AUTOTUNE

# Load training dataset
train_dataset = tf.keras.utils.image_dataset_from_directory(
    train_dir,
    shuffle=True,
    batch_size=BATCH_SIZE,
    image_size=IMG_SIZE
)

# Load validation dataset
validation_dataset = tf.keras.utils.image_dataset_from_directory(
    validation_dir,
    shuffle=True,
    batch_size=BATCH_SIZE,
    image_size=IMG_SIZE
)

class_names = train_dataset.class_names
print(f"\nClass names: {class_names}")

# Visualize sample images from the dataset
plt.figure(figsize=(10, 10))
for images, labels in train_dataset.take(1):
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.title(class_names[labels[i]])
        plt.axis("off")
plt.suptitle("Sample Images from the Dataset", fontsize=16)
plt.show()

# Set up preprocessing
preprocess_input = tf.keras.applications.vgg16.preprocess_input

# Optimize dataset performance
train_dataset = train_dataset.cache().prefetch(buffer_size=BUFFER_SIZE)
validation_dataset = validation_dataset.cache().prefetch(buffer_size=BUFFER_SIZE)

# Load pre-trained VGG16 model
base_model = VGG16(input_shape=IMG_SIZE + (3,),
                   include_top=False,
                   weights='imagenet')

# Freeze the base model
base_model.trainable = False

# Add custom layers on top
global_average_layer = layers.GlobalAveragePooling2D()
prediction_layer = layers.Dense(1, activation='sigmoid')

# Build the complete model
inputs = tf.keras.Input(shape=(224, 224, 3))
x = preprocess_input(inputs)
x = base_model(x, training=False)
x = global_average_layer(x)
outputs = prediction_layer(x)

model = tf.keras.Model(inputs, outputs)

print("VGG16-based Transfer Learning Model Summary:")
model.summary()

# Compile the model
base_learning_rate = 0.0001
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),
              loss=tf.keras.losses.BinaryCrossentropy(),
              metrics=['accuracy'])

# Train the model
initial_epochs = 10
print(f"\nStarting model training for {initial_epochs} epochs...")
history = model.fit(
    train_dataset,
    epochs=initial_epochs,
    validation_data=validation_dataset
)
print("Model training complete!")

# Evaluate the model
loss, accuracy = model.evaluate(validation_dataset)
print(f"\nModel Test Accuracy: {accuracy*100:.2f}%")
print(f"Model Test Loss: {loss:.4f}")

# Extract training history
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss_history = history.history['loss']
val_loss_history = history.history['val_loss']
epochs_range = range(initial_epochs)

# Plot training and validation metrics
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss_history, label='Training Loss')
plt.plot(epochs_range, val_loss_history, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')

plt.show()

# Make predictions on a batch of validation images
test_images, test_labels = next(iter(validation_dataset))
predictions = model.predict(test_images)
predicted_labels = (predictions > 0.5).astype("int32")

# Convert labels to class names
true_labels_names = [class_names[i] for i in test_labels.numpy()]
predicted_labels_names = [class_names[i] for i in predicted_labels.flatten()]

# Visualize predictions
plt.figure(figsize=(15, 8))
num_images_to_show = min(len(test_images), 15)

for i in range(num_images_to_show):
    plt.subplot(3, 5, i + 1)
    plt.imshow(test_images[i].numpy().astype("uint8"))
    plt.title(f"True: {true_labels_names[i]}\nPred: {predicted_labels_names[i]}",
              color='green' if true_labels_names[i] == predicted_labels_names[i] else 'red')
    plt.axis("off")

plt.suptitle("Sample Predictions (Green: Correct, Red: Incorrect)", fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()
