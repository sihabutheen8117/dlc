!pip install h5py tensorflow-datasets

# Import necessary libraries
import numpy as np
import tensorflow as tf
from tensorflow import keras
import tensorflow_datasets as tfds

# Load and preprocess the text dataset (IMDb)
print("Loading and preparing IMDb dataset...")
(train_data, test_data), info = tfds.load(
    'imdb_reviews', 
    split=[tfds.Split.TRAIN, tfds.Split.TEST], 
    as_supervised=True, 
    with_info=True
)

# Extract sentences and labels
train_sentences = [sent.numpy().decode('utf8') for sent, _ in train_data]
train_labels_list = [label.numpy() for _, label in train_data]
test_sentences = [sent.numpy().decode('utf8') for sent, _ in test_data]
test_labels_list = [label.numpy() for _, label in test_data]

# Set parameters
vocab_size = 10000
max_length = 100
embedding_dim = 64
oov_tok = '<OOV>'

# Tokenize and pad sequences
tokenizer = keras.preprocessing.text.Tokenizer(num_words=vocab_size, oov_token=oov_tok)
tokenizer.fit_on_texts(train_sentences)

train_sequences = tokenizer.texts_to_sequences(train_sentences)
test_sequences = tokenizer.texts_to_sequences(test_sentences)

train_padded = keras.preprocessing.sequence.pad_sequences(
    train_sequences, 
    maxlen=max_length, 
    padding='post', 
    truncating='post'
)
test_padded = keras.preprocessing.sequence.pad_sequences(
    test_sequences, 
    maxlen=max_length, 
    padding='post', 
    truncating='post'
)

train_labels = np.array(train_labels_list)
test_labels = np.array(test_labels_list)

print("Data loaded, tokenized, and padded.")
print(f"Train data shape: {train_padded.shape}, Test data shape: {test_padded.shape}")

# Build SimpleRNN model
print("\nBuilding SimpleRNN model...")
model = keras.models.Sequential([
    keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),
    keras.layers.SimpleRNN(embedding_dim),
    keras.layers.Dense(1, activation='sigmoid')
])
model.summary()

# Compile model
print("\nCompiling model...")
model.compile(loss="binary_crossentropy", optimizer="adam", metrics=["accuracy"])

# Train the model
print("\nTraining model...")
epochs = 10
history = model.fit(
    train_padded, 
    train_labels, 
    epochs=epochs,
    validation_data=(test_padded, test_labels), 
    verbose=1
)
print("Model training complete.")

# Evaluate the model
print("\nEvaluating model on test data...")
loss, accuracy = model.evaluate(test_padded, test_labels, verbose=0)
print(f"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}")

# Predict sentiment for new inputs
print("\nPredicting sentiment for new inputs...")

def predict_sentiment(text):
    sequence = tokenizer.texts_to_sequences([text])
    padded_sequence = keras.preprocessing.sequence.pad_sequences(
        sequence, 
        maxlen=max_length, 
        padding='post', 
        truncating='post'
    )
    prediction = model.predict(padded_sequence, verbose=0)[0][0]
    sentiment = "Positive" if prediction >= 0.5 else "Negative"
    return sentiment, prediction

# Test with sample reviews
new_reviews = [
    "This film was a breathtaking masterpiece, truly exceptional!",
    "Utterly dreadful, a complete waste of two hours.",
    "It was decent, but nothing to write home about.",
]

for i, review in enumerate(new_reviews):
    sentiment, score = predict_sentiment(review)
    print(f"Review {i+1}: \"{review}\"\n  -> Sentiment: {sentiment} (Score: {score:.4f})\n")

print("Experiment complete.")
